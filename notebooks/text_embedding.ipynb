{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: text2phonemesequence in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (0.1.4)\n",
      "Requirement already satisfied: segments in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from text2phonemesequence) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from text2phonemesequence) (4.67.1)\n",
      "Requirement already satisfied: transformers in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from text2phonemesequence) (4.50.0)\n",
      "Requirement already satisfied: regex in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from segments->text2phonemesequence) (2024.11.6)\n",
      "Requirement already satisfied: csvw>=1.5.6 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from segments->text2phonemesequence) (3.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from transformers->text2phonemesequence) (24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from transformers->text2phonemesequence) (2.1.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from transformers->text2phonemesequence) (0.29.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from transformers->text2phonemesequence) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from transformers->text2phonemesequence) (0.5.3)\n",
      "Requirement already satisfied: filelock in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from transformers->text2phonemesequence) (3.17.0)\n",
      "Requirement already satisfied: requests in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from transformers->text2phonemesequence) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from transformers->text2phonemesequence) (6.0.2)\n",
      "Requirement already satisfied: rdflib in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (7.1.3)\n",
      "Requirement already satisfied: language-tags in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (1.2.0)\n",
      "Requirement already satisfied: colorama in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (0.4.6)\n",
      "Requirement already satisfied: isodate in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (0.7.2)\n",
      "Requirement already satisfied: uritemplate>=3.0.0 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (4.1.1)\n",
      "Requirement already satisfied: babel in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (2.17.0)\n",
      "Requirement already satisfied: jsonschema in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (4.23.0)\n",
      "Requirement already satisfied: attrs>=18.1 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (25.3.0)\n",
      "Requirement already satisfied: rfc3986<2 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from csvw>=1.5.6->segments->text2phonemesequence) (2.9.0.post0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers->text2phonemesequence) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers->text2phonemesequence) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from requests->transformers->text2phonemesequence) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from requests->transformers->text2phonemesequence) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from requests->transformers->text2phonemesequence) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from requests->transformers->text2phonemesequence) (2025.1.31)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from jsonschema->csvw>=1.5.6->segments->text2phonemesequence) (0.23.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from jsonschema->csvw>=1.5.6->segments->text2phonemesequence) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from jsonschema->csvw>=1.5.6->segments->text2phonemesequence) (0.36.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from python-dateutil->csvw>=1.5.6->segments->text2phonemesequence) (1.17.0)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /home/default/ML/speech-cloning/venv/lib/python3.10/site-packages (from rdflib->csvw>=1.5.6->segments->text2phonemesequence) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install text2phonemesequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/xphonebert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.roberta.modeling_roberta.RobertaModel'>\n",
      "<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from text2phonemesequence import Text2PhonemeSequence\n",
    "\n",
    "# Load XPhoneBERT model and its tokenizer\n",
    "xphonebert = AutoModel.from_pretrained(\"vinai/xphonebert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/xphonebert-base\")\n",
    "\n",
    "print(type(xphonebert))\n",
    "print(type(tokenizer))\n",
    "\n",
    "# Load Text2PhonemeSequence\n",
    "text2phone_model = Text2PhonemeSequence(language='eng-us', is_cuda=True)\n",
    "\n",
    "# Input sequence that is already WORD-SEGMENTED (and text-normalized if applicable)\n",
    "  \n",
    "sentence = \"This is deep learning project .\"\n",
    "\n",
    "input_phonemes = text2phone_model.infer_sentence(sentence)\n",
    "\n",
    "input_ids = tokenizer(input_phonemes, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = xphonebert(**input_ids)\n",
    "    phoneme_embeddings = outputs.last_hidden_state  # [1, T, 768]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ˈð ɪ s ▁ ˈɪ z ▁ ˈd i p ▁ ˈɫ ɝ n ɪ ŋ ▁ ˈp ɹ ɑ d ʒ ɛ k t ▁ .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_phonemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  0,  72,  12,   9,   4,  48,  27,   4,  99,   8,  21,   4, 135,  67,\n",
       "           5,  12,  35,   4, 100,  36,  31,  11,  60,  17,  13,   7,   4,  33,\n",
       "           2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 29, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.2162), tensor(-3.5025))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(phoneme_embeddings), torch.min(phoneme_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22272,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dist = phoneme_embeddings.reshape(-1).numpy()\n",
    "print(dist.shape)\n",
    "plt.hist(dist, bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4388), tensor(-0.5060))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after normalization\n",
    "\n",
    "phoneme_embeddings = phoneme_embeddings / torch.norm(phoneme_embeddings, dim=-1, keepdim=True)\n",
    "\n",
    "torch.max(phoneme_embeddings), torch.min(phoneme_embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
